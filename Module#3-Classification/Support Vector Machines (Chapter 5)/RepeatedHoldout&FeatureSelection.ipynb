{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "110e2dc4-4407-4d20-be4e-2dc012208870",
   "metadata": {},
   "source": [
    "# Copyright\n",
    "\n",
    "This lecture is prepared by Samir Abdelrahman and Adam Kotter. Also, few contents include few links and websites that are cited and used during the lecture.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8f8e78",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "\n",
    "We will run through a full example of model development, including the following steps:\n",
    "1. Problem selection\n",
    "2. Dataset evaluation\n",
    "3. Dataset cleaning\n",
    "4. Cross validation\n",
    "5. Selecting which model type to use (with statistics!)\n",
    "6. Selecting which features to use\n",
    "\n",
    "Please think about how these concepts apply to your group project during the lecture.  \n",
    "This lecture is to give the students: hands-on activities on cross-validation, pair-wise test bewteen several classifiers, and the introduction to feature selection. Please study the below medium-length links."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e24a3ac",
   "metadata": {},
   "source": [
    "# Define a problem statement and goals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822e91dc-da67-4e66-abaa-15aa37794234",
   "metadata": {},
   "source": [
    "Why do we want to use this dataset?  \n",
    "Which feature do we want to predict to accomplish our goal?  \n",
    "Do we want to predict classes (classifier) or predict values (regressor)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804c64f1",
   "metadata": {},
   "source": [
    "# [Understand the dataset and features](https://archive.ics.uci.edu/ml/datasets/hepatitis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b818384",
   "metadata": {},
   "source": [
    "## Features\n",
    "   \n",
    "     1. Class: DIE, LIVE\n",
    "     2. AGE: 10, 20, 30, 40, 50, 60, 70, 80\n",
    "     3. SEX: male, female\n",
    "     4. STEROID: no, yes\n",
    "     5. ANTIVIRALS: no, yes\n",
    "     6. FATIGUE: no, yes\n",
    "     7. MALAISE: no, yes\n",
    "     8. ANOREXIA: no, yes\n",
    "     9. LIVER BIG: no, yes\n",
    "    10. LIVER FIRM: no, yes\n",
    "    11. SPLEEN PALPABLE: no, yes\n",
    "    12. SPIDERS: no, yes\n",
    "    13. ASCITES: no, yes\n",
    "    14. VARICES: no, yes\n",
    "    15. BILIRUBIN: 0.39, 0.80, 1.20, 2.00, 3.00, 4.00\n",
    "    16. ALK PHOSPHATE: 33, 80, 120, 160, 200, 250\n",
    "    17. SGOT: 13, 100, 200, 300, 400, 500, \n",
    "    18. ALBUMIN: 2.1, 3.0, 3.8, 4.5, 5.0, 6.0\n",
    "    19. PROTIME: 10, 20, 30, 40, 50, 60, 70, 80, 90\n",
    "    20. HISTOLOGY: no, yes\n",
    "\n",
    "The values listed above \"represent so called \"boundary\" values; according to these \"boundary\" values the attribute can be discretized. At the same time, because of the continious attribute, one can perform some other test since the continuous information is preserved.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0278f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from scipy.stats import loguniform\n",
    "from statistics import mean\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings \n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report,f1_score\n",
    "from sklearn.impute import SimpleImputer \n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scikit_posthocs import posthoc_nemenyi_friedman\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce916866",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfcf1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load a CSV with data into a DataFrame object; we use commas to denote the thousands place, and any values marked with a ? are considered missing\n",
    "data = pd.read_csv('~/DATA/hepatitis.csv', thousands=',', na_values='?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f28982",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2292d6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb48d59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the above there is no datatype object that contradicts with the above description from the link\n",
    "# We want to use the first feature (Class) as our outcome, so we will skip that when defining our features\n",
    "allFeatures=data.columns[1:len(data.columns)]\n",
    "# We need to separate the categorical features from the numeric features; this is done based on manual inspection of the dataset\n",
    "catFeatures=data.columns[list(range(2,14))+list(range(19,20))]\n",
    "# To make sure we don't miss any features, we use list comprehension syntax to get every feature in allFeatures that isn't already in catFeatures\n",
    "numFeatures= [feature for feature in allFeatures if not(feature in catFeatures)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fc8212",
   "metadata": {},
   "outputs": [],
   "source": [
    "numFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9977d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "catFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58214351",
   "metadata": {},
   "source": [
    "# Descriptive analysis\n",
    "What does the data look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4c5752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What shape do the numeric features in the data have?\n",
    "data[numFeatures].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d907f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does a visual description of the numeric data look like?\n",
    "data[numFeatures].hist(figsize=(7.50, 7.50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f650bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does the distribution of categorical data look like?\n",
    "\n",
    "# This is to make the plot look better\n",
    "plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "# This loops through each categorical feature and visually plots it\n",
    "for cat in catFeatures:\n",
    "    fig, ax = plt.subplots()\n",
    "    data[cat].value_counts().plot(ax=ax, kind='bar', xlabel=cat, ylabel='frequency')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41bde38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How imbalanced is our dataset?\n",
    "data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce4c986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define X and y for our models here\n",
    "X = data[data.columns[1:20]]\n",
    "y = data[data.columns[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e04692",
   "metadata": {},
   "source": [
    "# Developing Imputer and Standardized Scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6aea024-9bd0-4327-a994-4d8e65ab0294",
   "metadata": {},
   "source": [
    "Our imputer fills in missing data for us. Many algorithms will break if they hit a missing value, so we need to find a way to put in a \"best guess\" for what the missing values would be.  \n",
    "Our scaler brings all of the data into a more uniform range without losing information so that features can be compared more easily to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78af53e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This imputer fills missing values with the mode of the data; this works better for discretized data than for continuous data\n",
    "imp_mode = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "# This imputer fills missing values with the mean of the data; this only works for continuous data\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "# This scaler has not been trained yet\n",
    "scaler=StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62379c15",
   "metadata": {},
   "source": [
    "# Developing baseline and ensemble classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7422b54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we define all of the classifiers we want to test along with strings representing their human-readably names\n",
    "baselineClassifiers=[LogisticRegression(), SVC(), KNeighborsClassifier(),DecisionTreeClassifier()]\n",
    "nameBaselineClassifiers=['LR','SVC','KNN','DT']\n",
    "\n",
    "# This section just puts all of the classifiers together with their names in a single list\n",
    "estimators=[]\n",
    "for bc in range(0,len(baselineClassifiers)):\n",
    "    estimators.append((nameBaselineClassifiers[bc],baselineClassifiers[bc]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba6f947",
   "metadata": {},
   "source": [
    "# Splitting the data: Use any Splitting Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f218ed0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this example we use a randomized version of stratified k-fold splitting; this preserves the percentage of samples in each class for each split\n",
    "number_of_splits=5\n",
    "sss = StratifiedShuffleSplit(n_splits=number_of_splits, test_size=0.3, random_state=0)\n",
    "# We set random_state above so that we get the same results every time we run the code\n",
    "train_indexes=[]\n",
    "test_indexes=[]\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    train_indexes.append(train_index)\n",
    "    test_indexes.append(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ee438f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results={}    # We initialize a dictionary to hold testing results for each classifier\n",
    "for bc in range(0,len(baselineClassifiers)):    # The variable 'bc' is an integer representing the index value of each classifier\n",
    "    print(nameBaselineClassifiers[bc])\n",
    "    results[nameBaselineClassifiers[bc]]=[]    # We create a dictionary entry based on the human-readable name of the classifier\n",
    "    for tr,te in zip(train_indexes,test_indexes):\n",
    "        X_train, X_test = X.iloc[tr], X.iloc[te]\n",
    "        y_train, y_test = y.iloc[tr], y.iloc[te]\n",
    "        \n",
    "        # Imputation\n",
    "        imp_mode.fit(X_train[catFeatures])    # We replace missing categorical values with the most common value in their feature\n",
    "        imp_mean.fit(X_train[numFeatures])    # We replace missing numeric values with the mean of their feature\n",
    "        X_train[catFeatures]=imp_mode.transform(X_train[catFeatures])\n",
    "        X_test[catFeatures]=imp_mode.transform(X_test[catFeatures])\n",
    "        X_train[numFeatures]=imp_mean.transform(X_train[numFeatures])\n",
    "        X_test[numFeatures]=imp_mean.transform(X_test[numFeatures])\n",
    "    \n",
    "        # Scaling numeric features\n",
    "        scaler.fit(X_train[numFeatures])    # We need to train the scaler on the training data before we can scale the training or testing sets\n",
    "        X_train[numFeatures]=scaler.transform(X_train[numFeatures])\n",
    "        X_test[numFeatures]=scaler.transform(X_test[numFeatures])\n",
    "    \n",
    "        # Encoding the Categorical features\n",
    "        # This step is necessary if any categorical features have more than two possible values\n",
    "        X_train=pd.get_dummies(X_train)\n",
    "        X_test=pd.get_dummies(X_test)\n",
    "        X_test = X_test.reindex(columns = X_train.columns, fill_value=0)\n",
    "        \n",
    "        # Train and test the model on the scaled and imputed data\n",
    "        model = baselineClassifiers[bc].fit(X_train,y_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        f1_value = f1_score(y_test,y_test_pred,average='micro')\n",
    "        print(f1_value)    # We base model performance on F1-score; 'micro' behaves like 'binary' when we only have two classes\n",
    "        results[nameBaselineClassifiers[bc]].append(f1_value)\n",
    "    print('The average of the classifier\\'s F1-score results', np.average(results[nameBaselineClassifiers[bc]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad736e1",
   "metadata": {},
   "source": [
    "# Which classifier is the best based on the mean of repeated 1 holdout cross-validation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7bc98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=''\n",
    "maximum=float('-inf')\n",
    "# Go through the name of each classifier to find the one with the best results in the 'results' dictionary\n",
    "for nameClassifier in results.keys():\n",
    "    avg=np.average(results[nameClassifier])\n",
    "    if (avg > maximum):    # Save the average value as a potential maximum if it is greater than every previous average value\n",
    "        maximum=avg\n",
    "        maxClassifier=nameClassifier\n",
    "\n",
    "print('The classifier {0} is the minumm average of {1}'.format(maxClassifier,maximum))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cb48db-4a02-42e4-a389-b4aa8f21b0ef",
   "metadata": {},
   "source": [
    "# Is the best classifier actually significantly better than the other classifiers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a378d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_significance=[]\n",
    "for nameClassifier in results.keys():\n",
    "    test_significance.append(results[nameClassifier])\n",
    "\n",
    "#Check if Friedman test is signifiant\n",
    "chi_square,p_value_mean=stats.friedmanchisquare(*test_significance)\n",
    "print(p_value_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cf0c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If a significant difference exists, we can check for pairwise significant differences\n",
    "trans_groups=np.array(test_significance).T\n",
    "p=posthoc_nemenyi_friedman(trans_groups)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a9f2af",
   "metadata": {},
   "source": [
    "# Feature selection methods \n",
    "\n",
    "\n",
    "What is the differences between feature selection methods, dimensionality reduction, and feature extraction?\n",
    "\n",
    "\n",
    "\n",
    "Resources are [link1](https://towardsdatascience.com/feature-selection-for-machine-learning-3-categories-and-12-methods-6a4403f86543)\n",
    "\n",
    "In [Sklearn](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89788ef4",
   "metadata": {},
   "source": [
    "## Feature selection \n",
    "\n",
    "1. It eliminates irrelevant and noisy features by keeping the ones with minimum redundancy and maximum relevance to the target variable.\n",
    "2. It reduces the computational time and complexity of training and testing a classifier, so it results in more cost-effective models.\n",
    "3. It improves learning algorithms’ performance, avoids overfitting, and helps to create better general models.\n",
    "\n",
    "There are three categories of feature selection methods, depending on how they interact with the classifier, namely: \n",
    "1. filter.\n",
    "2. wrapper.\n",
    "3. embedded methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb05460",
   "metadata": {},
   "source": [
    "### Filter methods \n",
    "\n",
    "They are scalable (up to very high-dimensional data) and perform fast feature selection before classification so that the bias of a learning algorithm does not interact with the bias of the feature selection algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394086dd",
   "metadata": {},
   "source": [
    "#### Chi-square\n",
    "\n",
    "If the target variable is independent of the feature, then it gets a low score, or if they are dependent, the feature is important. A higher value of chi-square means that the feature is more relevant concerning the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa5724e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "chi_selector = SelectKBest(chi2, k=15)  # We're using the 15 best features here; use k='all' if you need to rank all \n",
    "\n",
    "results={}\n",
    "for bc in range(0,len(baselineClassifiers)):\n",
    "    print(nameBaselineClassifiers[bc])\n",
    "    results[nameBaselineClassifiers[bc]]=[]\n",
    "    for tr,te in zip(train_indexes,test_indexes):\n",
    "        X_train, X_test = X.iloc[tr], X.iloc[te]\n",
    "        y_train, y_test = y.iloc[tr], y.iloc[te]\n",
    "        \n",
    "        #Imputation\n",
    "        imp_mode.fit(X_train[catFeatures])\n",
    "        imp_mean.fit(X_train[numFeatures])\n",
    "        X_train[catFeatures]=imp_mode.transform(X_train[catFeatures])\n",
    "        X_test[catFeatures]=imp_mode.transform(X_test[catFeatures])\n",
    "        X_train[numFeatures]=imp_mean.transform(X_train[numFeatures])\n",
    "        X_test[numFeatures]=imp_mean.transform(X_test[numFeatures])\n",
    "        \n",
    "        cols=X_train.columns\n",
    "    \n",
    "        #Feature Selection\n",
    "        chi_selector.fit(X_train,y_train)\n",
    "        X_train=chi_selector.transform(X_train)\n",
    "        X_test=chi_selector.transform(X_test)\n",
    "        \n",
    "        column_names = cols[chi_selector.get_support()]\n",
    "        \n",
    "        X_train=pd.DataFrame(X_train,columns=column_names)\n",
    "        X_test=pd.DataFrame(X_test,columns=column_names)    \n",
    "        newNumFeaturs=[num for num in numFeatures if num in column_names]\n",
    "        newCatFeaturs=[num for num in catFeatures if num in column_names]\n",
    "            \n",
    "        #Scaling numeric features\n",
    "        scaler.fit(X_train[newNumFeaturs])\n",
    "        X_train[newNumFeaturs]=scaler.transform(X_train[newNumFeaturs])\n",
    "        X_test[newNumFeaturs]=scaler.transform(X_test[newNumFeaturs])\n",
    "    \n",
    "        #Encoding the Categorical features\n",
    "        X_train=pd.get_dummies(X_train,columns=newCatFeaturs)\n",
    "        X_test=pd.get_dummies(X_test,columns=newCatFeaturs)\n",
    "        X_test = X_test.reindex(columns = X_train.columns, fill_value=0)\n",
    "        \n",
    "        \n",
    "        model=baselineClassifiers[bc].fit(X_train,y_train)\n",
    "        y_test_pred=model.predict(X_test)\n",
    "        f1_value=f1_score(y_test,y_test_pred,average='micro')\n",
    "        print(f1_value)\n",
    "        results[nameBaselineClassifiers[bc]].append(f1_value)\n",
    "    print('The average of the classifier\\'s F1-score results',np.average(results[nameBaselineClassifiers[bc]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92eb6fc4",
   "metadata": {
    "tags": []
   },
   "source": [
    "####  Mutual Information\n",
    "\n",
    "From sklearn:  \n",
    "\"Mutual information between two random variables is a non-negative value, which measures the dependency between the variables. It is equal to zero if and only if two random variables are independent, and higher values mean higher dependency.\"\n",
    "\n",
    "A feature is considered relevant if it has a high information gain. It cannot handle redundant features, because features are selected in a univariate way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88da1968",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "me_selector = SelectKBest(mutual_info_classif, k=15)  # We're using the 15 best features here; use k='all' if you need to rank all \n",
    "\n",
    "results={}\n",
    "for bc in range(0,len(baselineClassifiers)):\n",
    "    print(nameBaselineClassifiers[bc])\n",
    "    results[nameBaselineClassifiers[bc]]=[]\n",
    "    for tr,te in zip(train_indexes,test_indexes):\n",
    "        X_train, X_test = X.iloc[tr], X.iloc[te]\n",
    "        y_train, y_test = y.iloc[tr], y.iloc[te]\n",
    "        \n",
    "        #Imputation\n",
    "        imp_mode.fit(X_train[catFeatures])\n",
    "        imp_mean.fit(X_train[numFeatures])\n",
    "        X_train[catFeatures]=imp_mode.transform(X_train[catFeatures])\n",
    "        X_test[catFeatures]=imp_mode.transform(X_test[catFeatures])\n",
    "        X_train[numFeatures]=imp_mean.transform(X_train[numFeatures])\n",
    "        X_test[numFeatures]=imp_mean.transform(X_test[numFeatures])\n",
    "        \n",
    "        cols=X_train.columns\n",
    "    \n",
    "        #Feature Selection\n",
    "        me_selector.fit(X_train,y_train)\n",
    "        X_train=me_selector.transform(X_train)\n",
    "        X_test=me_selector.transform(X_test)\n",
    "        \n",
    "        column_names = cols[me_selector.get_support()]\n",
    "        \n",
    "        X_train=pd.DataFrame(X_train,columns=column_names)\n",
    "        X_test=pd.DataFrame(X_test,columns=column_names)    \n",
    "        newNumFeaturs=[num for num in numFeatures if num in column_names]\n",
    "        newCatFeaturs=[num for num in catFeatures if num in column_names]\n",
    "            \n",
    "        #Scaling numeric features\n",
    "        scaler.fit(X_train[newNumFeaturs])\n",
    "        X_train[newNumFeaturs]=scaler.transform(X_train[newNumFeaturs])\n",
    "        X_test[newNumFeaturs]=scaler.transform(X_test[newNumFeaturs])\n",
    "    \n",
    "        #Encoding the Categorical features\n",
    "        X_train=pd.get_dummies(X_train,columns=newCatFeaturs)\n",
    "        X_test=pd.get_dummies(X_test,columns=newCatFeaturs)\n",
    "        X_test = X_test.reindex(columns = X_train.columns, fill_value=0)\n",
    "        \n",
    "        \n",
    "        model=baselineClassifiers[bc].fit(X_train,y_train)\n",
    "        y_test_pred=model.predict(X_test)\n",
    "        f1_value=f1_score(y_test,y_test_pred,average='micro')\n",
    "        print(f1_value)\n",
    "        results[nameBaselineClassifiers[bc]].append(f1_value)\n",
    "    print('The average of the classifiers\\'results',np.average(results[nameBaselineClassifiers[bc]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b1e63c",
   "metadata": {},
   "source": [
    "###  Wrapper methods\n",
    "\n",
    "The widely used wrapper method uses an algorithm to train the model iteratively and each time removes the least important feature using the weights of the algorithm as the criterion.\n",
    "It is a multivariate method in the sense that it evaluates the relevance of several features considered jointly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c48ea8a",
   "metadata": {},
   "source": [
    "## Using from scipy.stats feature selection\n",
    "\n",
    "1. [Mann–Whitney U test](https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test)\n",
    "2. [Chi-Squared test](https://en.wikipedia.org/wiki/Chi-squared_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a580bddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an example of using a chi-square filter method\n",
    "\n",
    "from scipy.stats import mannwhitneyu,chi2_contingency,chi2\n",
    "\n",
    "results={}\n",
    "for bc in range(0,len(baselineClassifiers)):\n",
    "    print(nameBaselineClassifiers[bc])\n",
    "    results[nameBaselineClassifiers[bc]]=[]\n",
    "    for tr,te in zip(train_indexes,test_indexes):\n",
    "        X_train, X_test = X.iloc[tr], X.iloc[te]\n",
    "        y_train, y_test = y.iloc[tr], y.iloc[te]\n",
    "        \n",
    "        #Imputation\n",
    "        imp_mode.fit(X_train[catFeatures])\n",
    "        imp_mean.fit(X_train[numFeatures])\n",
    "        X_train[catFeatures]=imp_mode.transform(X_train[catFeatures])\n",
    "        X_test[catFeatures]=imp_mode.transform(X_test[catFeatures])\n",
    "        X_train[numFeatures]=imp_mean.transform(X_train[numFeatures])\n",
    "        X_test[numFeatures]=imp_mean.transform(X_test[numFeatures])\n",
    "        \n",
    "        # Remove all insignificant categorical features from consideration\n",
    "        newCatFeatures=[]\n",
    "        for fe in catFeatures:\n",
    "            table=pd.crosstab(X_train[fe].to_numpy().flatten(), y_train.to_numpy().flatten())\n",
    "            _, p, _, _ = chi2_contingency(table)\n",
    "            if (p <=0.05):\n",
    "                 newCatFeatures.append(fe) \n",
    "        \n",
    "        # Remove all insignificant numeric features from consideration\n",
    "        newNumFeatures=[]\n",
    "        for fe in numFeatures:\n",
    "            _, p = mannwhitneyu(X_train[fe].to_numpy().flatten(), y_train.to_numpy().flatten())\n",
    "            if (p <=0.05):\n",
    "                newNumFeatures.append(fe)\n",
    "    \n",
    "        #print('Feature Selection')\n",
    "        #print(numFeatures)\n",
    "        #print(catFeatures)\n",
    "        #print(newNumFeatures)\n",
    "        #print(newCatFeatures)\n",
    "        #input('Feature Selection')\n",
    "        \n",
    "\n",
    "        X_train=X_train[newNumFeatures+newCatFeatures]\n",
    "        X_test=X_test[newNumFeatures+newCatFeatures]\n",
    "        \n",
    "        #Scaling numeric features\n",
    "        scaler.fit(X_train[newNumFeatures])\n",
    "        X_train[newNumFeatures]=scaler.transform(X_train[newNumFeatures])\n",
    "        X_test[newNumFeatures]=scaler.transform(X_test[newNumFeatures])\n",
    "    \n",
    "        #Encoding the Categorical features\n",
    "        X_train=pd.get_dummies(X_train)\n",
    "        X_test=pd.get_dummies(X_test)\n",
    "        X_test = X_test.reindex(columns = X_train.columns, fill_value=0)\n",
    "        \n",
    "        \n",
    "        model=baselineClassifiers[bc].fit(X_train,y_train)\n",
    "        y_test_pred=model.predict(X_test)\n",
    "        f1_value=f1_score(y_test,y_test_pred,average='micro')\n",
    "        print(f1_value)\n",
    "        results[nameBaselineClassifiers[bc]].append(f1_value)\n",
    "    print('The average of the classifiers\\'results',np.average(results[nameBaselineClassifiers[bc]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0a881b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
