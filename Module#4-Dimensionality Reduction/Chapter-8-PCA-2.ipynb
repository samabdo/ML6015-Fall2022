{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35e4b1f5",
   "metadata": {},
   "source": [
    "# Resources\n",
    "\n",
    "1. The book Chapter 8\n",
    "2. A good [link](https://aiaspirant.com/types-of-pca/)\n",
    "\n",
    "# Types of PCA\n",
    "1. PCA\n",
    "2. Sparse PCA\n",
    "3. Randomized PCA\n",
    "4. Incremental PCA\n",
    "5. Kernel PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9882b225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df224bf",
   "metadata": {},
   "source": [
    "# [MNIST Database](https://en.wikipedia.org/wiki/MNIST_database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a611a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d070e2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    " X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, stratify=y,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d427f441",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in X.columns:\n",
    "    print(c,X[c].min(),X[c].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a694dac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of X:', X.shape, '\\n', 'Shape of y:', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6865bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc9beb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.iloc[1].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ad4b34",
   "metadata": {},
   "source": [
    "# Data Standardization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c8db33",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train = sc.transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ae8c56",
   "metadata": {},
   "source": [
    "# Baseline classifier with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8454ef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF=RandomForestClassifier()\n",
    "RF.fit(X_train,y_train)\n",
    "yhat=RF.predict(X_test)\n",
    "f1_all=f1_score(y_test,yhat,average='macro')\n",
    "print(f1_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bd08d1",
   "metadata": {},
   "source": [
    "# PCA-2-components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e19f05",
   "metadata": {},
   "source": [
    "## PCA-2-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61807023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_plot(X_trans, y):\n",
    "    X_p = pd.DataFrame(data = X_trans, columns=['PC1','PC2'])\n",
    "    X_p['Label'] = y\n",
    "    sns.lmplot(x=\"PC1\", y=\"PC2\", hue=\"Label\", data=X_p, fit_reg=False)\n",
    "    ax = plt.gca()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6b184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "scatter_plot(X_train_pca, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0c919a",
   "metadata": {},
   "source": [
    "## PCA-2-testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab4fdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pca = pca.transform(X_test)\n",
    "scatter_plot(X_test_pca, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca94c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF=RandomForestClassifier()\n",
    "RF.fit(X_train_pca,y_train)\n",
    "yhat=RF.predict(X_test_pca)\n",
    "f1_pca_2=f1_score(y_test,yhat,average='macro')\n",
    "print(f1_pca_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666445c4",
   "metadata": {},
   "source": [
    "# PCA-0.98-explained_variance_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb61b721",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, stratify=y,random_state=42)\n",
    "pca = PCA()\n",
    "pca.fit(X_train)\n",
    "total_explained_variance = pca.explained_variance_ratio_.cumsum()\n",
    "print(total_explained_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b5b100",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(total_explained_variance)\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706e3ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_over_98 = len(total_explained_variance[total_explained_variance >= .98])\n",
    "n_to_reach_98 = X_train.shape[1]-n_over_98 + 1\n",
    "print('Number features: {}\\tTotal Variance Explained: {}'.format(n_to_reach_98, total_explained_variance[n_to_reach_98-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aab31ea",
   "metadata": {},
   "source": [
    "## Retrained the data and compare with the original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d6b354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the components and projected images\n",
    "pca = PCA(154)\n",
    "pca.fit(X_train)\n",
    "X_98 = pca.transform(X_train)\n",
    "projected = pca.inverse_transform(X_98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80363f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "fig, ax = plt.subplots(2, 10, figsize=(10, 2.5),\n",
    "                       subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                       gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "for i in range(10):\n",
    "    ax[0, i].imshow(X_train.iloc[i].values.reshape((28,28)), cmap='binary_r')\n",
    "    ax[1, i].imshow(projected[i].reshape((28,28)), cmap='binary_r')\n",
    "    \n",
    "ax[0, 0].set_ylabel('full-dim\\ninput')\n",
    "ax[1, 0].set_ylabel('150-dim\\nreconstruction');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a26b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_98 = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ed9079",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF=RandomForestClassifier()\n",
    "RF.fit(X_98,y_train)\n",
    "yhat=RF.predict(X_test_98)\n",
    "f1_pca_98=f1_score(y_test,yhat,average='macro')\n",
    "print(f1_pca_98)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8ae6c6",
   "metadata": {},
   "source": [
    "# [SPARSE PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.SparsePCA.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba2416d",
   "metadata": {},
   "source": [
    "Contemporary datasets often have the number of input variables $p$ comparable with or even much larger than the number of samples $n$. It has been shown that if $p/n$ does not converge to zero, the classical PCA is not consistent. But sparse PCA can retain consistency even if $p>>n$. A particular disadvantage of ordinary PCA is that the principal components are usually linear combinations of all input variables. Sparse PCA overcomes this disadvantage by finding linear combinations that contain just a few input variables. Sparse PCA is a variant of PCA which attempts to produce easily interpretable models through sparse loading. \n",
    "\n",
    "\n",
    "Example, for machine learning problems like gene analytics, each axis might correspond to a specific gene. In such cases, if most of the entries in the loadings are zeros, we can easily interpret the model and understand the physical meaning of the loading as well as the principal components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06f4cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import SparsePCA\n",
    "help(SparsePCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b3c5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, stratify=y,random_state=42)\n",
    "spca = SparsePCA(n_components=2, alpha=0.0001)\n",
    "X_spca = spca.fit_transform(X_train)\n",
    " \n",
    "scatter_plot(X_spca, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d0e694",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_spca = spca.transform(X_test)\n",
    "scatter_plot(X_test_spca, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3be0fa",
   "metadata": {},
   "source": [
    "# [Randomized PCA](https://scikit-learn.org/0.15/modules/generated/sklearn.decomposition.RandomizedPCA.html)\n",
    "\n",
    "\n",
    "The classical PCA uses the low-rank matrix approximation to estimate the principal components. However, this method becomes costly and makes the whole process difficult to scale, for large datasets.\n",
    "\n",
    "\n",
    "This method is Principal component analysis (PCA) using randomized SVD. Linear dimensionality reduction using approximated Singular Value Decomposition of the data and keeping only the most significant singular vectors to project the data to a lower dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1979add3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, stratify=y,random_state=42)\n",
    "\n",
    "\n",
    "rpca = PCA(n_components=2, svd_solver='randomized')\n",
    "X_rpca = rpca.fit_transform(X_train)\n",
    " \n",
    "scatter_plot(X_rpca, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31db97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_rpca = rpca.transform(X_test)\n",
    "scatter_plot(X_test_rpca, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3545fb0a",
   "metadata": {},
   "source": [
    "# INCREMENTAL PCA\n",
    "\n",
    "Incremental PCA can be used when the dataset is too large to fit in the memory.\n",
    "\n",
    "Here we split the dataset into mini-batches where each batch can fit into the memory and then feed it one mini-batch at a moment to the IPCA algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c6d879",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, stratify=y,random_state=42)\n",
    " \n",
    "ipca = IncrementalPCA(n_components=2, batch_size=500)\n",
    "X_ipca = ipca.fit_transform(X_train)\n",
    " \n",
    "scatter_plot(X_ipca, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d674d792",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_ipca = ipca.transform(X_test)\n",
    "scatter_plot(X_test_ipca, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f30f65",
   "metadata": {},
   "source": [
    "# KERNEL PCA\n",
    "\n",
    "PCA is a linear method. It works great for linearly separable datasets. However, if the dataset has non-linear relationships, then it produces undesirable results.\n",
    "\n",
    "Kernel PCA is a technique which uses the so-called kernel trick and projects the linearly inseparable data into a higher dimension where it is linearly separable.\n",
    "\n",
    "There are various kernels that are popularly used; some of them are linear, polynomial, RBF, and sigmoid.\n",
    "\n",
    "Let’s create a dataset using sklearn’s make_circles which is not linearly separable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a08c9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    " \n",
    "X,y = make_circles(n_samples=500, factor=.1, noise=0.02, random_state=47)\n",
    " \n",
    "plt.scatter(X[:,0], X[:,1], c=y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bad273",
   "metadata": {},
   "source": [
    "## Applying PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28ddf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    " \n",
    "plt.title(\"PCA\")\n",
    "plt.scatter(X_pca[:,0], X_pca[:,1], c=y)\n",
    "plt.xlabel(\"Component 1\")\n",
    "plt.ylabel(\"Component 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe144e0",
   "metadata": {},
   "source": [
    "## Applying Kernel PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd1ce1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kpca = KernelPCA(kernel='rbf', gamma=1)\n",
    "X_kpca = kpca.fit_transform(X)\n",
    " \n",
    "plt.title(\"Kernel PCA\")\n",
    "plt.scatter(X_kpca[:,0], X_kpca[:,1], c=y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b47ecf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aaa6c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
