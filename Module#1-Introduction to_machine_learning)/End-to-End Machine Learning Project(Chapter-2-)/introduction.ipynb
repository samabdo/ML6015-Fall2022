{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20a9a482",
   "metadata": {},
   "source": [
    "# Readings\n",
    "\n",
    "1. Chapter 2 in the syllabus book 1 covers the materials in this notebook and related notebooks. As guidelines for your readings, you may want to: \n",
    "    - Study first the notebooks and then read the related topics in Chapter 2 and web links for more knowledge. Or\n",
    "    - Read Chapter 2 to get broad vision and then study the notebooks and go through the web links when you need.\n",
    "2. Try to practice the code in Chapter 2 book 1 GiHub. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5a3f40",
   "metadata": {},
   "source": [
    "# Revision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ae085c",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Consider you have dataset with 10 million data points. Select one of the following learning strategy combination that will be most adequate to fit with your data size and explain why â€“ Assume the data quality is excellent!\n",
    "\n",
    "a. Batch and instance-based learning.   \n",
    "b. Batch and model-based learning.     \n",
    "c. On-line and instance-based learning.      \n",
    "d. On-line and model-based learning.      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be6ed17",
   "metadata": {},
   "source": [
    "## Specific Questions\n",
    "\n",
    "1. What is the [multicollinearity](https://en.wikipedia.org/wiki/Multicollinearity)? how does this problem affect the modeling?\n",
    "\n",
    "2. What is the difference between prediction and classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e991e8a",
   "metadata": {},
   "source": [
    "## General Questions (See the book, lectures, and discussions)\n",
    "\n",
    "1. What are the advantages and disadvantages to use rule-based and ML algorithms?\n",
    "2. What are the advantages and disadvantages of learning on the fly versus with/without model strategies?\n",
    "3. What are the challenges of unsupervised and supervised learning algorithm?\n",
    "4. How do you know that the model is over-fitted or under-fitted? \n",
    "    - How to deal with these two problems?\n",
    "5. What is the no free lunch (NFL) theorem?\n",
    "6. What is the role of training, validation, and testing the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ace96b6",
   "metadata": {},
   "source": [
    "# General Guide\n",
    "\n",
    "In this jupyter notebook:\n",
    "1. Some items in the table of contents are described totally in this notebook. Others are just links to other jupyter notebooks located in the same folder of this notebook-- you need to click on each link to open it in a new window of the related notebook. \n",
    "2. We use some hyper-links for citation purpose <b> only </b> and they are optional for the student to read. It is preferable for the student to read those links cited as <b> Extra Readings </b>.\n",
    "3. The student wants to understand not to memorize Chapter 2 concepts. The Chapter is full of concepts that will be used during the whole course. The student also may want to understand not memorize the code written in the jupyter notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bc92b5",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "\n",
    "To understand the following concepts:\n",
    "1. The differences among data splitting techniques.\n",
    "2. Feature engineering main steps.\n",
    "3. How to implement Grid/Random search in sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985a7ef2",
   "metadata": {},
   "source": [
    "# Copyright\n",
    "\n",
    "## Copyright holder\n",
    "\n",
    "Most of the contents of this lectures are taken/modified from the book:\n",
    "\"Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow Concepts, Tools, and Techniques to\n",
    "Build Intelligent Systems\"-- [link](https://www.amazon.com/Hands-Machine-Learning-Scikit-Learn-TensorFlow/dp/1492032646). Other contents are either developed by the instructor or taken from web links that are cited in the contexts.      \n",
    "\n",
    "## The Course materials copyright\n",
    "\n",
    "The Content is made available only for your personal, noncommercial educational, and scholarly use. You may not use the Content for any other purpose, or distribute, post or make the Content available to others unless you obtain any required permission from the copyright holder. Some Content may be provided via streaming or other means that restrict copying; you may not circumvent those restrictions. You may not alter or remove any copyright or other proprietary notices included in the Content. You need to take the permission from the above copyright holder to use the materials and to check the complete Course Materials Copyright section in the course canvas website, as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0221fa",
   "metadata": {},
   "source": [
    "# The conceptual view of machine learning pipeline\n",
    "\n",
    "<img style=\"float: center\" src=\"./images/pipeline_sa.png\" alt=\"drawing\" Hight=\"300\" width=\"600\"/>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853e250f",
   "metadata": {},
   "source": [
    "# Data splitting techniques\n",
    "\n",
    "## [Hold-out cross-validation][1]\n",
    "\n",
    "Split the data randomly into training, validation/development, and test/unseen parts randomly: usually 60%, 20%, and 20% respectively or any other splitting techniques:\n",
    "1. Training set: Data set to build/fit the model.\n",
    "2. Validation/development set: Data set to evaluate the learning algorithm with different configurations. It is called development set, since we are using it while developing our model. It can be a bit biased, that's why we need the third kind of data set.\n",
    "3. Test/unseen set: Data set to check the accuracy of the final model and get the unbiased results.\n",
    "\n",
    "#### hold-out cross-validation: notes</span>\n",
    "1. It is a simple algorithm but we could not use it to prove model generalization.\n",
    "\n",
    "## [K-fold cross-validation][2]\n",
    "\n",
    "We usually split the data into K=10 folds (the size of each fold is 1/K) such that: \n",
    "1. for each fold i where i = 1,2,...K, do:\n",
    "    1. train the learner on all folds except i.\n",
    "    2. Use the ith fold for testing the model in (1) and report the performance results.\n",
    "2. Average the model performance results in the K iterations in step (1)\n",
    "\n",
    "### Kfold cross-validation: notes</span>\n",
    "1. It is an in-place and computaionally doable algorithm but we could use it to prove model generalization on the population.\n",
    "\n",
    "<img style=\"float: center\" src=\"./images/kfold-cross-validation.jpg\" alt=\"drawing\" Hight=\"300\" width=\"500\"/> \n",
    "\n",
    "\n",
    "## [Bootstrapping cross-validation][3]\n",
    "\n",
    "\n",
    "1. Choose a number of bootstrap samples to perform. //Usually 100,200,..., or 1000 repetitions \n",
    "2. Choose a sample size. // Usually a sample size = the size of population.\n",
    "3. For each bootstrap sample:\n",
    "   1. Randomly draw a sample with replacement (in-the-bag training sample) with the chosen size:\n",
    "       - While the size of the sample is less than the chosen size:\n",
    "            - Randomly select an observation from the dataset\n",
    "            - Add it to the sample (i.e., In-the-bag training sample).\n",
    "   2. Fit a model on the data sample\n",
    "   3. Estimate the model performance on the remaining unselected observations (the out-of-bag sample).\n",
    "4. Calculate the average of the model performance results in all bootstrap samples in step (3).\n",
    "\n",
    "\n",
    "### Bootstrapping: notes\n",
    "1. We use [0.632 bootstrap rule][4] in which the in-the-bag sample has 63.2% distinct observations and the out-the-bag sample has the remaining 38.8% observations.\n",
    "2. It is a computationally extensive and out-of-place algorithm and we could use it to prove model generalization on the simulated population.\n",
    "\n",
    "\n",
    "<img style=\"float: center\" src=\"./images/bootstrap-example.jpg\" alt=\"drawing\" Hight=\"100\" width=\"300\"/> \n",
    "\n",
    "\n",
    "## [Repeated cross validation][5]\n",
    "\n",
    "Repeated k-fold cross-validation provides a way to improve the estimated performance of a machine learning model. This involves simply repeating the cross-validation procedure multiple times and reporting the mean result across all folds from all runs. \n",
    "\n",
    "[1]: https://www.mff.cuni.cz/veda/konference/wds/proc/pdf10/WDS10_105_i1_Reitermanova.pdf\n",
    "[2]: https://en.wikipedia.org/wiki/Cross-validation_(statistics)\n",
    "[3]:https://machinelearningmastery.com/a-gentle-introduction-to-the-bootstrap-method/\n",
    "[4]:http://rasbt.github.io/mlxtend/user_guide/evaluate/bootstrap_point632_score/\n",
    "[5]:https://machinelearningmastery.com/repeated-k-fold-cross-validation-with-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a775e430",
   "metadata": {},
   "source": [
    "## Cross-validation code examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e87de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline \n",
    "\n",
    "np.random.seed(0)  # For reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ed6905",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv(\"~/DATA/Iris.csv\")  # Load the data\n",
    "X = iris[iris.columns[1:5]]\n",
    "y = iris[iris.columns[5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb845fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3b0572",
   "metadata": {},
   "source": [
    "### Holdout cross-validation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97946ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hold-out cross-validation\n",
    "\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,shuffle=True)\n",
    "print (X_train.shape, y_train.shape)\n",
    "print (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b799041",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c0310a",
   "metadata": {},
   "source": [
    "### Kfold cross-validation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0713fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10-fold cross-validation\n",
    "\n",
    "cv = KFold(n_splits=2, random_state=42, shuffle=True)\n",
    "for train_index, test_index in cv.split(X):\n",
    "    print(\"Train Index: \", train_index, \"\\n\")\n",
    "    print(\"Test Index: \", test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1926d6",
   "metadata": {},
   "source": [
    "### Bootstrapping cross-validation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f6b7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrapping cross-validation\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "Index=range(0,len(X))\n",
    "\n",
    "\n",
    "boot = resample(Index, replace=True, n_samples=len(Index), random_state=1)\n",
    "print(len(X),len(set(boot)))\n",
    "print(len(set(boot))/len(X)*100.0)\n",
    "\n",
    "\n",
    "print('\\nBootstrap Sample: %s' % boot)\n",
    "# out of bag observations\n",
    "oob = [x for x in Index if x not in boot]\n",
    "print('OOB Sample: %s' % oob)\n",
    "print(len(oob)/len(X)*100.0) # out of bag \n",
    "print(len(oob),len(boot))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c513c7b7",
   "metadata": {},
   "source": [
    "### [Example to show the difference between repeated Kfold and Kfold](https://machinelearningmastery.com/repeated-k-fold-cross-validation-with-python/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6f2126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test classification dataset\n",
    "from sklearn.datasets import make_classification\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
    "# summarize the dataset\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7998315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a logistic regression model using k-fold cross-validation\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# create dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
    "# prepare the cross-validation procedure\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "# create model\n",
    "model = LogisticRegression()\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e08ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a logistic regression model using repeated k-fold cross-validation\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# prepare the cross-validation procedure\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# create model\n",
    "model = LogisticRegression()\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b6a9e3",
   "metadata": {},
   "source": [
    "### Exercise \n",
    "**When to use:**\n",
    "1. Hold-out\n",
    "2. K-fold\n",
    "3. Bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e5a4f9",
   "metadata": {},
   "source": [
    "# <a href=\"./feature engineering-New.ipynb\">Feature engineering</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af06ed42",
   "metadata": {},
   "source": [
    "# Pipeline code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305c459b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline \n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "np.random.seed(0)  # For reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3d6de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"~/DATA/adult.csv\",na_values='?')  # Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abac1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd164fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9921db95",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7d6c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = df._get_numeric_data().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d0d0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd644fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f744ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a28d9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols=list(set(cols) - set(num_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b264f47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042d9740",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.columns[-1]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ae8abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydict={\"<=50K\":1,\">50K\":0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb0cf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace({df.columns[-1]:mydict},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924f6d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df[df.columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68aaa9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fba28a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd22a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8cfadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hold-out cross-validation\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,shuffle=True)\n",
    "print (X_train.shape, y_train.shape)\n",
    "print (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de74b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "myTrainCa = [value for value in cat_cols if value in X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e5924d",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_transformer = Pipeline(steps=[\n",
    "        ('standard', StandardScaler())])\n",
    "\n",
    "minmax_transformer = Pipeline(steps=[\n",
    "        ('minmax', MinMaxScaler())])\n",
    "\n",
    "onehot_transformer=Pipeline(steps=[\n",
    "        ('onehot', OneHotEncoder())])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "        remainder='passthrough', #passthough features not listed\n",
    "        transformers=[\n",
    "            ('std', standard_transformer , num_cols[1:3]),\n",
    "            ('mm', minmax_transformer , num_cols[3:]),\n",
    "            ('ohe', onehot_transformer , myTrainCa),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e496a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d05ff07",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', LogisticRegression())])\n",
    "\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"The accuracy model score: %.3f\" % clf.score(X_test, y_test))\n",
    "y_preds = clf.predict(X_test)\n",
    "print(y_preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8929481",
   "metadata": {},
   "source": [
    "# <a href=\"./hyper-parameter optimization.ipynb\">Hyper-parameter optimization</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43470f29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
